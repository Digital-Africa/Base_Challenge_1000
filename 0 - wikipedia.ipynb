{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "import model_lib \n",
    "\n",
    "hostname = 'https://en.wikipedia.org{}'\n",
    "\n",
    "def get_wiki(cat):\n",
    "    to_drop = ['','CS1: long volume value','Categories','Category',\n",
    " 'Talk',\n",
    " 'Contributions',\n",
    " 'Article',\n",
    " 'Read',\n",
    " 'Main page',\n",
    " 'Contents',\n",
    " 'Current events',\n",
    " 'Random article',\n",
    " 'About Wikipedia',\n",
    " 'Contact us',\n",
    " 'Donate',\n",
    " 'Help',\n",
    " 'Community portal',\n",
    " 'Recent changes',\n",
    " 'Upload file',\n",
    " 'What links here',\n",
    " 'Related changes',\n",
    " 'Special pages',\n",
    " 'Wikidata item',\n",
    " 'Edit links',\n",
    " 'Creative Commons Attribution-ShareAlike License',\n",
    " 'Terms of Use',\n",
    " 'Privacy Policy',\n",
    " 'Privacy policy',\n",
    " 'Disclaimers',\n",
    " 'Contact Wikipedia',\n",
    " 'Developers',\n",
    " 'Cookie statement',\n",
    "  'Library cataloging',\n",
    " 'classification']\n",
    "    res = requests.get(cat)\n",
    "    soup = bs(res.text, \"html.parser\")\n",
    "    category = {}\n",
    "    articles = {}\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        url = link.get(\"href\", \"\")\n",
    "        if \"/wiki/Category\" in url:\n",
    "            category[link.text.strip()] = url\n",
    "        if \"/wiki/\" in url:\n",
    "            articles[link.text.strip()] = url\n",
    "    category = {k:hostname.format(category[k]) for k in category.keys() if k not in to_drop and 'CS1' not in k and 'wiki' not in k.lower() and 'wikipedia.org' not in category[k].lower()}\n",
    "    articles = {k:hostname.format(articles[k]) for k in articles.keys() if k not in to_drop and 'CS1' not in k and 'wiki' not in k.lower() and 'wikipedia.org' not in articles[k].lower() and 'Category:' not in articles[k]}\n",
    "    return category, articles\n",
    "\n",
    "def articles_content(url):\n",
    "    import re\n",
    "    def striphtml(data):\n",
    "        p = re.compile(r'<.*?>')\n",
    "        return p.sub('', data)\n",
    "    page = urllib.request.urlopen(url)\n",
    "    soup = bs(page, \"lxml\")\n",
    "    content = soup.find_all('p')\n",
    "\n",
    "\n",
    "\n",
    "    output = ''\n",
    "    blacklist = [\n",
    "        '[document]',\n",
    "        'noscript',\n",
    "        'header',\n",
    "        'html',\n",
    "        'meta',\n",
    "        'head', \n",
    "        'input',\n",
    "        'script',\n",
    "        # there may be more elements you don't want, such as \"style\", etc.\n",
    "    ]\n",
    "\n",
    "    for t in content:\n",
    "        if t.parent.name not in blacklist:\n",
    "            output += '{} '.format(t)\n",
    "\n",
    "    return striphtml(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "list_categories = ['https://en.wikipedia.org/wiki/Category:Agriculture','https://en.wikipedia.org/wiki/Nutrient_management']\n",
    "categories, articles = {},{}\n",
    "for e in list_categories:\n",
    "    cat, art = get_wiki(e)\n",
    "    categories = {**categories,**cat}\n",
    "    articles = {**articles,**art}\n",
    "print(len(articles))\n",
    "url = articles['Agriculture']\n",
    "print(url)\n",
    "articles_content(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_categorie = ['Agriculture', 'Energy', 'Health']\n",
    "list_categories = ['https://en.wikipedia.org/wiki/Category:{}'.format(ctgr) for ctgr in target_categorie]\n",
    "cat, art = get_wiki(list_categories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://en.wikipedia.org/wiki/Category:Agricultural_finance' in list(cat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_wiki_terms(target, url):\n",
    "    dict_links[target].append(url)\n",
    "    \n",
    "actors_agriculture = ['productors', 'market', 'investment', 'logistic', 'transformation']\n",
    "dict_links = {e: [] for e in actors_agriculture}\n",
    "update_wiki_terms('productors', 'https://en.wikipedia.org/wiki/Farmer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Farmer']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_links['productors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['History', 'History of organic farming', 'Neolithic Revolution', 'Agriculture in Mesoamerica', 'Austronesian Expansion', 'Ancient Egyptian agriculture', 'Agriculture in ancient Greece', 'Agriculture in ancient Rome', 'Arab Agricultural Revolution', 'British Agricultural Revolution', 'Green Revolution', 'Chinampa', 'Monoculture', 'On land', 'Animal husbandry', 'cattle', 'pigs', 'poultry', 'sheep', 'Dairy', 'Dryland', 'Extensive', 'Fertilizer', 'Free-range', 'Grazing', 'Convertible husbandry', 'Rotational grazing', 'Hobby', 'Intensive', 'animals', 'crops', 'Natural', 'Orchard', 'Organic', 'Paddy field', 'Ranching', 'Sharecropping', 'Slash-and-burn', 'Terrace', 'Steam sterilization', 'Hydroculture', 'Aquaculture', 'Aquaponics', 'Hydroponics', 'Aeroponics', 'Agribusiness', 'Agricultural engineering', 'Agricultural machinery', 'Agricultural science', 'Agricultural technology', 'Agroecology', 'Agroforestry', 'Agronomy', 'Animal-free', 'Crop diversity', 'Ecology', 'Mechanisation', 'Permaculture', 'Sustainable', 'Urban', 'Government ministries', 'Universities and colleges', 'Agriculture portal', 'v', 't', 'economy', 'farmland', 'agriculture', 'wealth', 'hunter and gatherer', 'horticultural', 'industrial society', 'Fertile Crescent region', 'Middle East', 'climate change', 'gift-giving', 'East Asia', 'Small-scale agriculture', 'Bronze Age', 'density of population', 'social complexity', 'civilization', 'infection', 'industrial societies', 'city-states', 'Middle Ages', 'Venice', 'Florence', 'Milan', 'Genoa', 'Western Europe', 'United States of America', 'Industrial Revolution', 'crop breeding', 'soil nutrients', 'weed control', 'mechanization', 'tractor', 'sowing', 'harvesting', 'threshing', 'livestock', 'Rome', 'Baghdad', 'Sicily', 'North Africa', 'Southern France', 'famines', 'landownership', 'stratification', 'masses', 'slavery', 'serfdom', 'peonage', 'common good', 'public interest', 'Caste systems', 'biomass', 'photosynthesis', 'Agropedia portal', 'Agrarian socialism', 'Agrarian system', 'Developing country', 'Pre-industrial society', 'Traditional society']\n",
      "125\n",
      "[('expire', 159), ('exotic', 119), ('excite', 97), ('gela', 96), ('envelop', 92)]\n",
      "[('specialty', 0.7694089218154968), ('turf', 0.6995736623172649), ('innovate', 0.5263785024608866), ('heterogeneity', 0.5234955672692985), ('embellish', 0.5021668138033152)]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Agrarian_society'\n",
    "_, articles = get_wiki(url)\n",
    "print(list(articles.keys()))\n",
    "\n",
    "print(len(articles))\n",
    "corpus = [articles_content(articles[a]) for a in  articles]\n",
    "\n",
    "lemm_corpus = [model_lib.Lemm(X = art, file = 'stopwords_agri.txt').X for art in corpus]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfid_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "tfid = tfid_vectorizer.fit_transform(lemm_corpus)\n",
    "tf = tf_vectorizer.fit_transform(lemm_corpus)\n",
    "tfid_feature_name = tfid_vectorizer.get_feature_names()\n",
    "tf_feature_name = tf_vectorizer.get_feature_names()\n",
    "\n",
    "print(sorted([a for a in zip(tf_feature_name,tf.tocoo().data)], key = lambda x: x[1], reverse = True)[:5])\n",
    "print(sorted([a for a in zip(tfid_feature_name,tfid.tocoo().data)], key = lambda x: x[1], reverse = True)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Agrarian_society'\n",
    "_, articles = get_wiki(url)\n",
    "print(list(articles.keys()))\n",
    "\n",
    "print(len(articles))\n",
    "corpus = [articles_content(articles[a]) for a in  articles]\n",
    "\n",
    "lemm_corpus = [model_lib.Lemm(X = art, file = 'stopwords_agri.txt').X for art in corpus]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfid_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "tfid = tfid_vectorizer.fit_transform(lemm_corpus)\n",
    "tf = tf_vectorizer.fit_transform(lemm_corpus)\n",
    "tfid_feature_name = tfid_vectorizer.get_feature_names()\n",
    "tf_feature_name = tf_vectorizer.get_feature_names()\n",
    "\n",
    "print(sorted([a for a in zip(tf_feature_name,tf.tocoo().data)], key = lambda x: x[1], reverse = True)[:5])\n",
    "print(sorted([a for a in zip(tfid_feature_name,tfid.tocoo().data)], key = lambda x: x[1], reverse = True)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chalenge1000\n",
    "Chalenge = chalenge1000.Native()\n",
    "df = Chalenge.X\n",
    "corpus = df[df['categorie'] == 'agriculture'][['nom_struc', 'categorie']].join(Chalenge.descriptions_trad)[['prez_struc', 'prez_produit_struc']].fillna('').agg(sum, axis = 1).values.tolist()\n",
    "\n",
    "lemm_corpus = [model_lib.Lemm(X = art, file = 'stopwords_agri.txt').X for art in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product', 'farmer', 'production', 'food', 'agricultural', 'market', 'farm', 'produce', 'service', 'local']\n",
      "[('product', 1264), ('farmer', 767), ('production', 740), ('food', 726), ('agricultural', 622), ('market', 609), ('farm', 555), ('produce', 507), ('service', 394), ('local', 374)]\n",
      "[('farmer', 1), ('production', 1), ('produce', 1), ('service', 1), ('local', 1), ('product', 2), ('food', 2), ('agricultural', 3), ('market', 3), ('farm', 9)]\n",
      "[('market', 0.09666378190669922), ('agricultural', 0.11658972476503757), ('service', 0.22664184546291313), ('produce', 0.2812619214967012), ('production', 0.31418096826340136), ('farmer', 0.3285048893111314), ('food', 0.4910943413136987), ('local', 0.6502495878823172), ('product', 0.7431024187885659), ('farm', 0.9201022523327803)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfid_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, vocabulary = vocab)\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, vocabulary = vocab)\n",
    "tfid = tfid_vectorizer.fit_transform(lemm_corpus)\n",
    "tf = tf_vectorizer.fit_transform(lemm_corpus)\n",
    "tfid_feature_name = tfid_vectorizer.get_feature_names()\n",
    "tf_feature_name = tf_vectorizer.get_feature_names()\n",
    "print(vocab)\n",
    "print(collections.Counter(' '.join(lemm_corpus).split()).most_common(10))\n",
    "print(sorted([a for a in zip(tf_feature_name,tf.tocoo().data)], key = lambda x: x[1], reverse = False))\n",
    "print(sorted([a for a in zip(tfid_feature_name,tfid.tocoo().data)], key = lambda x: x[1], reverse = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('product', 2), ('production', 1)]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a for a in zip(tf_feature_name,tf.tocoo().data) if 'product' in a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('product', 0.7431024187885659), ('production', 0.31418096826340136)]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a for a in zip(tfid_feature_name,tfid.tocoo().data) if 'product' in a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "vocab = [a for a,b in collections.Counter(' '.join(lemm_corpus).split()).most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

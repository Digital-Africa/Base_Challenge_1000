{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_lib\n",
    "import chalenge1000\n",
    "import numpy as np\n",
    "import collections\n",
    "import functools\n",
    "import operator\n",
    "import time\n",
    "import progressbar\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, HTML\n",
    "from statistics import median\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class perf_model(object):\n",
    "    import model_lib\n",
    "    import chalenge1000\n",
    "    import numpy as np\n",
    "    import collections\n",
    "    import functools\n",
    "    import operator\n",
    "    from operator import itemgetter\n",
    "    import pandas\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from IPython.display import display, HTML\n",
    "    from statistics import median\n",
    "    import time\n",
    "    import progressbar\n",
    "    \"\"\"docstring for perf_model\"\"\"\n",
    "    def __init__(self, categories, test_size, silent=True):\n",
    "        self.categories = categories\n",
    "        self.test_size = test_size\n",
    "        self.df = self.get_df()\n",
    "        self.silent = silent\n",
    "\n",
    "\n",
    "    def get_df(self):\n",
    "        lemm = lambda x: model_lib.Lemm(x,file = 'stopwords_agri.txt').X\n",
    "        lexic = lambda x: ' '.join([a for a,b in collections.Counter(x.split()).most_common(10000)])\n",
    "        word_count = lambda x: {a:b for a,b in collections.Counter(x.split()).most_common(10000)}       \n",
    "\n",
    "        challenge = chalenge1000.Native()\n",
    "        df_cat_temp = challenge.text\n",
    "        \n",
    "        df_trad = challenge.descriptions_trad\n",
    "        df_trad['corpus'] = df_trad[['prez_struc', 'prez_produit_struc']].agg(sum, axis = 1)\n",
    "        df_trad['corpus_lemm'] = df_trad['corpus'].map(lemm)\n",
    "        df_trad['lexic_lemm'] = df_trad['corpus_lemm'].map(lexic)\n",
    "        df_trad['word_weight'] = df_trad['corpus_lemm'].map(word_count)\n",
    "\n",
    "        df = df_trad.join(df_cat_temp['temp']).join(challenge.X['categorie'])\n",
    "        df.columns = ['prez_struc', 'prez_produit_struc', 'prez_marche_struc',\n",
    "       'prez_zone_struc', 'prez_objectif_struc', 'prez_innovante_struc',\n",
    "       'prez_duplicable_struc', 'prez_durable_struc', 'corpus', 'corpus_lemm',\n",
    "       'lexic_lemm', 'word_weight', 'temp', 'cat_struc']\n",
    "\n",
    "        return df\n",
    "\n",
    "    def lexic_extractor(self):\n",
    "        lex1 = collections.Counter(self.df[self.df['cat_struc']== self.categories[0]]['lexic_lemm'].agg(sum, axis=0).split()).most_common(5000)\n",
    "        lex2 = collections.Counter(self.df[self.df['cat_struc']== self.categories[1]]['lexic_lemm'].agg(sum, axis=0).split()).most_common(5000)\n",
    "\n",
    "        len_cat1 = len(self.df[self.df['cat_struc']==self.categories[0]])\n",
    "        len_cat2 = len(self.df[self.df['cat_struc']==self.categories[1]])\n",
    "    \n",
    "        counter_cat1 = list({(a,b*100/len_cat1) for a,b in lex1}.union({(k,0) for k,l in lex2 if k not in [a for a,b in lex1]}))\n",
    "        counter_cat2 = list({(a,b*100/len_cat2) for a,b in lex2}.union({(k,0) for k,l in lex1 if k not in [a for a,b in lex2]}))\n",
    "\n",
    "        vocab = [a for a,b in counter_cat1]\n",
    "    \n",
    "        id = operator.itemgetter(0)\n",
    "    \n",
    "        weight_cat1 = self.df[self.df['cat_struc']== self.categories[0]]['word_weight']\n",
    "        weight_cat2 = self.df[self.df['cat_struc']== self.categories[1]]['word_weight']\n",
    "    \n",
    "        vocab_weight_cat1 = [(key, value/len_cat1) for key, value in dict(functools.reduce(operator.add, map(collections.Counter, weight_cat1))).items()]\n",
    "        vocab_weight_cat1  = list({i for i in vocab_weight_cat1 if id(i) in vocab}.union({(k, 0) for k in vocab if k not in [a for a,b in vocab_weight_cat1]}))\n",
    "\n",
    "        vocab_weight_cat2 = [(key, value/len_cat2) for key, value in dict(functools.reduce(operator.add, map(collections.Counter, weight_cat2))).items()]\n",
    "        vocab_weight_cat2  = list({i for i in vocab_weight_cat2 if id(i) in vocab}.union({(k, 0) for k in vocab if k not in [a for a,b in vocab_weight_cat2]}))\n",
    "    \n",
    "        id_counter_cat2 = {id(rec): rec[1:] for rec in counter_cat2}\n",
    "        id_vocab_weight_cat1 = {id(rec): rec[1:] for rec in vocab_weight_cat1}\n",
    "        id_vocab_weight_cat2 = {id(rec): rec[1:] for rec in vocab_weight_cat2}\n",
    "    \n",
    "        merged = [i + id_counter_cat2[id(i)] for i in counter_cat1 if id(i) in id_counter_cat2]\n",
    "        merged = [i + id_vocab_weight_cat1[id(i)] for i in merged if id(i) in id_vocab_weight_cat1]\n",
    "        merged = [i + id_vocab_weight_cat2[id(i)] for i in merged if id(i) in id_vocab_weight_cat2]\n",
    "\n",
    "        keyword_map = pandas.DataFrame(merged, columns = ['keyword','cat1', 'cat2', 'weight_cat1', 'weight_cat2'])\n",
    "    \n",
    "        def produit(x,y):\n",
    "            return x*(y+1)\n",
    "    \n",
    "        keyword_map['score_cat1'] = keyword_map.apply(lambda x: produit(x['cat1'], x['weight_cat1']), axis = 1)\n",
    "        keyword_map['score_cat2'] = keyword_map.apply(lambda x: produit(x['cat2'], x['weight_cat2']), axis = 1)\n",
    "        keyword_map['difference'] = abs(keyword_map['score_cat1'] - keyword_map['score_cat2'])\n",
    "        keyword_map.sort_values('difference', ascending = False)\n",
    "    \n",
    "        #percentile = pandas.DataFrame(keyword_map['difference'].quantile(np.linspace(.01, 1, 99, 00)))\n",
    "        #percentile['lag_diff'] = percentile.diff(axis = 0)\n",
    "    \n",
    "        pct = []\n",
    "        for i in range(1, 100):\n",
    "            i = i/100\n",
    "            j = i -0.01\n",
    "            temp = keyword_map['difference'].quantile(i)\n",
    "            diff = temp - keyword_map['difference'].quantile(j)\n",
    "            if i ==0.01: \n",
    "                pct.append([i, temp, abs(temp)/2])\n",
    "            else: \n",
    "                pct.append([i, temp, diff])\n",
    "        pct1 = pandas.DataFrame(pct, columns=['a', 'b', 'c'])\n",
    "        \n",
    "        if self.silent == False:\n",
    "            print(plt.scatter(pct1.index, pct1['c']))\n",
    "    \n",
    "        select = pct1[pct1['c']>pct1['c'].mean()]['a'].values.tolist()\n",
    "        \n",
    "        if self.silent == False:\n",
    "            print(select)\n",
    "    \n",
    "        def cible(liste):\n",
    "            for i in liste:\n",
    "                if i<=0.5:\n",
    "                    next\n",
    "                else:\n",
    "                    return i\n",
    "                    break\n",
    "    \n",
    "        quant = cible(select)\n",
    "\n",
    "        if self.silent == False:\n",
    "            print('Quantile sélectionné :', quant)\n",
    "    \n",
    "        lexic_model = [i for i in keyword_map[keyword_map['difference']>keyword_map['difference'].quantile(quant)]['keyword']]    \n",
    "        if self.silent == False:\n",
    "            print('Longueur du lexique :',len(lexic_model))\n",
    "    \n",
    "        dic_word_weight = keyword_map[['keyword', 'score_cat1', 'score_cat2']].set_index('keyword').T.to_dict('list')\n",
    "    \n",
    "        return lexic_model, dic_word_weight\n",
    "\n",
    "    def train_test(self, seed):\n",
    "        text_corpus_label = self.df[self.df['cat_struc'].isin(self.categories)][['corpus_lemm','cat_struc']]  \n",
    "        test,train = train_test_split(text_corpus_label, test_size = self.test_size, random_state = seed)\n",
    "        train = train['corpus_lemm']\n",
    "        test = test['corpus_lemm']      \n",
    "        return train, test\n",
    "\n",
    "    def perf_lda(self, train, test, model_param):\n",
    "        model = model_lib.Models(**model_param)    \n",
    "        models = model.run_model_LDA(train.values.tolist())\n",
    "        predict = pandas.DataFrame(model.reverse_lda(test.values.tolist(), models) , index =test.index)\n",
    "        #display(predict)\n",
    "        return models['LDA'], predict, models['LDA']['components']\n",
    "\n",
    "    def topic_to_category(self, components, vocab_weight):\n",
    "        topic_category = {}\n",
    "        for i in range(2):\n",
    "            words = components['Topic {}'.format(i)]\n",
    "            cat1 = []\n",
    "            cat2 = []\n",
    "            for j in words: \n",
    "                if j in vocab_weight.keys():\n",
    "                    cat1.append(vocab_weight[j][0])\n",
    "                    cat2.append(vocab_weight[j][1])\n",
    "            cat1 = sum(cat1)\n",
    "            cat2 = sum(cat2)\n",
    "            topic_category[i] = cat1 - cat2\n",
    "    \n",
    "        if topic_category[0]>topic_category[1]:\n",
    "            topic_category[0]= self.categories[0]\n",
    "            topic_category[1]= self.categories[1]\n",
    "        else:\n",
    "            topic_category[0]= self.categories[1]\n",
    "            topic_category[1]= self.categories[0]\n",
    "        \n",
    "        return topic_category\n",
    "\n",
    "    def precision(self, predict, topic_category):\n",
    "    \n",
    "        def get_topic(e):\n",
    "            if e >0:\n",
    "                return topic_category[0]\n",
    "            if e <0:\n",
    "                return topic_category[1]\n",
    "    \n",
    "        def true_positve(a,b):\n",
    "            if a == b:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        precision = predict.join(self.df['cat_struc'])\n",
    "        precision[0] = precision[0]*100\n",
    "        precision[1] = precision[1]*100\n",
    "        precision['topic'] = precision[0]-precision[1]\n",
    "        #display(predict)\n",
    "\n",
    "        precision['predict_label'] = precision['topic'].map(get_topic)\n",
    "        #display(predict)\n",
    "\n",
    "        precision['classification_kpi'] = precision.apply(lambda x: true_positve(x['cat_struc'],x['predict_label']), axis= 1)\n",
    "        #display(predict)\n",
    "\n",
    "        cat0 = precision[precision['cat_struc'] == self.categories[0]]\n",
    "        cat1 = precision[precision['cat_struc'] == self.categories[1]]\n",
    "\n",
    "        vrai_positif_cat0 = cat0['classification_kpi'].sum()/len(cat0)*100\n",
    "        vrai_positif_cat1 = cat1['classification_kpi'].sum()/len(cat1)*100\n",
    "\n",
    "        #print(model_parameters)\n",
    "    \n",
    "        if self.silent == False:\n",
    "            print('\\nPrécision vrai positif catégorie {}: {}'.format(categories[0], vrai_positif_cat0))\n",
    "    \n",
    "        if self.silent == False:\n",
    "            print('\\nPrécision vrai positif catégorie {}: {}'.format(categories[1], vrai_positif_cat1))\n",
    "    \n",
    "        #model_parameters.update({'precision':agri['classification_kpi'].sum()/len(agri)*100, 'vocabulaire': models['LDA']['feature_names']})\n",
    "        #errors = agri[agri['classification_kpi'] == 0].sort_values('topic')\n",
    "        #collections.Counter(' '.join(errors.join(text_corpus)['collection_counter'].values.tolist()).split()).most_common(10)\n",
    "        #return model_parameters, agri, other, models['LDA']\n",
    "    \n",
    "        return precision, vrai_positif_cat0, vrai_positif_cat1\n",
    "\n",
    "\n",
    "\n",
    "    def operation(self, model_param, vocab, vocab_weight):\n",
    "        #vocab, vocab_weight = self.lexic_extractor()\n",
    "        model_param.update({'vocabulary': vocab, 'n_features': len(vocab)})\n",
    "        #model_param['vocabulary'] = vocab\n",
    "        #model_param['n_features'] = len(vocab)\n",
    "\n",
    "        precision_param = []\n",
    "        output = {}\n",
    "\n",
    "        bar = progressbar.ProgressBar(maxval=99).start()\n",
    "\n",
    "        for i in range(100):\n",
    "            if self.silent == False:\n",
    "                print('\\n\\nItération numéro:', i)\n",
    "            train, test = self.train_test(i)\n",
    "            models, predict, components = self.perf_lda(train, test, model_param)\n",
    "            topic_category = self.topic_to_category(components, vocab_weight)\n",
    "            precis, vrai_positif_cat0, vrai_positif_cat1 = self.precision(predict, topic_category)\n",
    "            precision_param.append([vrai_positif_cat0, vrai_positif_cat1])\n",
    "            output.update({i: [train, test, models, precis]})\n",
    "            bar.update(i)\n",
    "\n",
    "        med_precision_param = [median([a for a,b in precision_param]), median([b for a,b in precision_param])]\n",
    "        print('\\nPrécision médiane des paramètres',med_precision_param)\n",
    "\n",
    "        df_precision_param = pandas.DataFrame(precision_param, columns = ['cat0', 'cat1'])\n",
    "        df_precision_param['sum'] =  df_precision_param[['cat0', 'cat1']].agg(sum, axis = 1)\n",
    "        best_seed = df_precision_param[df_precision_param['cat0']>df_precision_param['cat0'].quantile(0.90)]['sum'].idxmax()\n",
    "        print('\\nModèle le plus performant',best_seed)\n",
    "\n",
    "        return df_precision_param, med_precision_param, best_seed, output \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-10 11:16:14.369600\n",
      "0:00:41.218164\n"
     ]
    }
   ],
   "source": [
    "categories = ['agriculture', 'media']\n",
    "#model_parameters = {'n_components' : 2, 'n_top_words' : 500, 'doc_topic_prior':0.1}\n",
    "test_size = 0.8\n",
    "t0 = datetime.now()\n",
    "print(t0)\n",
    "perf = perf_model(categories, test_size)\n",
    "t1 = datetime.now()\n",
    "\n",
    "print(t1-t0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vocab_weight = perf.lexic_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression: 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Précision médiane des paramètres [94.89023870417732, 94.73684210526315]\n",
      "\n",
      "Modèle le plus performant 37\n",
      "Réalisé en: 161.796s\n",
      "Progression: 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Précision médiane des paramètres [94.81481481481482, 94.73684210526315]\n",
      "\n",
      "Modèle le plus performant 37\n",
      "Réalisé en: 180.341s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "perf_param = {}\n",
    "best_param = []\n",
    "\n",
    "for i in range(1,3):\n",
    "    t0 = time()\n",
    "    print('Progression: {}/{}'.format(i,len(range(1,3))))\n",
    "    alpha = i/10\n",
    "    model_parameters = {'n_components' : 2, 'n_top_words' : 500, 'n_features': len(vocab), 'doc_topic_prior':alpha}\n",
    "    df_precision_param, med_precision_param, best_seed, output = perf.operation(model_parameters, vocab, vocab_weight)\n",
    "    best_param.append(med_precision_param[0] + med_precision_param[1])\n",
    "    perf_param.update({i:{'precision_all_seed':df_precision_param, 'precision_param': med_precision_param, 'best_seed': best_seed, 'dic_output': output}})\n",
    "    print(\"Réalisé en: %0.3fs\" % (time() - t0))\n",
    "\n",
    "best_alpha = pandas.Series(best_param).idxmax() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['precision_all_seed', 'precision_param', 'best_seed', 'dic_output'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_param[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.242424</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>191.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>96.296296</td>\n",
       "      <td>186.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.552239</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>185.204413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.202899</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>194.202899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.571429</td>\n",
       "      <td>88.235294</td>\n",
       "      <td>176.806723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95.620438</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>190.620438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>95.714286</td>\n",
       "      <td>94.117647</td>\n",
       "      <td>189.831933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>96.376812</td>\n",
       "      <td>94.736842</td>\n",
       "      <td>191.113654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>92.753623</td>\n",
       "      <td>94.736842</td>\n",
       "      <td>187.490465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>94.244604</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>194.244604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cat0        cat1         sum\n",
       "0   99.242424   92.000000  191.242424\n",
       "1   90.000000   96.296296  186.296296\n",
       "2   89.552239   95.652174  185.204413\n",
       "3   94.202899  100.000000  194.202899\n",
       "4   88.571429   88.235294  176.806723\n",
       "..        ...         ...         ...\n",
       "95  95.620438   95.000000  190.620438\n",
       "96  95.714286   94.117647  189.831933\n",
       "97  96.376812   94.736842  191.113654\n",
       "98  92.753623   94.736842  187.490465\n",
       "99  94.244604  100.000000  194.244604\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_param[1]['precision_all_seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_soil(element):\n",
    "    if 'soil' in element or 'nutrient' in element:# or 'drone' in element or 'things' in element:\n",
    "        return True\n",
    "A = perf.df['corpus'].map(is_soil)\n",
    "A[A==True].to_frame().join(perf.df['corpus'], lsuffix='no_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
